{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the Data\n",
        "\n",
        "The best place we found for large-scale datasets of NBA player stats was NBA.com. However, it is paywalled/heavily limited in terms of access without a prior letter to their office, which we could not feasibly do. So, after some digging, we found the NBA_API github, which thankfully did have back-end access to the dataset we wanted to get. Right under this, are the 2 Colab Installations for nba_api(which is the aforementioned github repo), and tqdm, which is a progress bar that we used to track the progress of the download of the dataset."
      ],
      "metadata": {
        "id": "H2GL4T_nZILo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so_fTYzhhDdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d05f9d3-6fbd-489d-f1c1-231c61f35fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nba_api\n",
            "  Downloading nba_api-1.4.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.7/261.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi<2024.0.0,>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from nba_api) (2023.11.17)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from nba_api) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.10/dist-packages (from nba_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->nba_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->nba_api) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->nba_api) (2.0.7)\n",
            "Installing collected packages: nba_api\n",
            "Successfully installed nba_api-1.4.1\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "#installation of api access and tqdm for progress bar\n",
        "!pip install nba_api\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accessing the API\n",
        "\n",
        "Once we installed the 2 packages, we then imported the playercareerstats and static players.py datasets, pandas for data manipulation, tqdm to serve as a progress bar, and ReadTimeout to let us know if there were any issues with getting all of the data from the API. Then, we saved the end dataframe to a csv."
      ],
      "metadata": {
        "id": "szzGIuaGxPl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MrKMz3HUkmT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "d54d194f-fb47-44e7-98d9-0e2d991075ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nba_api'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3e5e23304762>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnba_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoints\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplayercareerstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnba_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nba_api'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from nba_api.stats.endpoints import playercareerstats\n",
        "from nba_api.stats.static import players\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from requests.exceptions import ReadTimeout\n",
        "\n",
        "\n",
        "#obtaining data from nba_api, standard json access and conversion code\n",
        "def fetch_player_career_stats(player_id, timeout=None):\n",
        "    max_retries = 3\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            player_career = playercareerstats.PlayerCareerStats(\n",
        "                player_id=player_id,\n",
        "                timeout=timeout\n",
        "            )\n",
        "            return player_career.get_data_frames()[0]\n",
        "        except ReadTimeout as e:\n",
        "            retries += 1\n",
        "            print(f\"Read timeout. Retrying... (Attempt {retries}/{max_retries})\")\n",
        "    raise Exception(\"Failed to fetch data after multiple retries.\")\n",
        "\n",
        "# Timeout\n",
        "timeout = 100\n",
        "\n",
        "# Get all players\n",
        "all_players = players.get_players()\n",
        "\n",
        "# Initialize an empty list to store player dfs\n",
        "career_dfs = []\n",
        "\n",
        "# using tqdm to measure conversion process\n",
        "for player in tqdm(all_players, desc=\"Processing Players\"):\n",
        "    player_id = player['id']\n",
        "\n",
        "    # Get player career stats with custom settings\n",
        "    try:\n",
        "        career_df = fetch_player_career_stats(\n",
        "            player_id=player_id,\n",
        "            timeout=timeout\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for Player ID {player_id}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # make sure df is applicable for our criteria of 5 Y period\n",
        "    if any((career_df['SEASON_ID'] >= '2018') & (career_df['SEASON_ID'] <= '2023')):\n",
        "\n",
        "        # Filter df for 2018-2023\n",
        "        mask = (career_df['SEASON_ID'] >= '2018') & (career_df['SEASON_ID'] <= '2023')\n",
        "        career_df_filtered = career_df.loc[mask].copy()\n",
        "\n",
        "        # Add player to df\n",
        "        career_df_filtered['Player_ID'] = player_id\n",
        "        career_df_filtered['Player_Name'] = player['full_name']\n",
        "\n",
        "        # Append df to the list\n",
        "        career_dfs.append(career_df_filtered)\n",
        "\n",
        "#combining all dfs\n",
        "all_players_df = pd.concat(career_dfs, ignore_index=True)\n",
        "\n",
        "#saving to csv\n",
        "all_players_df.to_csv('all_players_career_stats_2018_2023.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection\n",
        "After downloading the csv of player stats (it was a json but we converted it so we could easier integrate it with pandas), we ran some basic statistical tests on the numeric variables (since there were only 5 years anyway, so things like player name and years played would have a negative effect on the efficacy of the model). The goal here was to determine which values had the highest correlation to Assists, which were our value we were trying to predict."
      ],
      "metadata": {
        "id": "p1Ivn3PrYV98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_players_df = pd.read_csv(\"/content/all_players_career_stats_2018_2023.csv\")\n",
        "all_players_df.head()\n",
        "\n",
        "# Assuming your target variable is 'AST'\n",
        "target_variable = 'AST'\n",
        "\n",
        "# Calculate correlations with the target variable\n",
        "correlations = all_players_df.corr()[target_variable].abs().sort_values(ascending=False)\n",
        "\n",
        "# Print the top correlated features\n",
        "print(\"Top Correlated Features:\")\n",
        "print(correlations.head(8))\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "# Calculate correlations with the target variable\n",
        "correlations = all_players_df.corr()['AST'].abs().sort_values(ascending=False)\n",
        "\n",
        "# Select the top 8 correlated features\n",
        "selected_features = correlations.index[1:9]  # Excluding the target variable\n",
        "\n",
        "# Extract features and target\n",
        "X = all_players_df[selected_features]\n",
        "y = all_players_df['AST'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Initialize RFE\n",
        "rfe = RFE(model, n_features_to_select=8)  # Set the number of features you want to select\n",
        "\n",
        "# Fit RFE on the training data\n",
        "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "selected_features_rfe = X.columns[rfe.support_]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Top 8 Correlated Features:\", selected_features_rfe)\n"
      ],
      "metadata": {
        "id": "XEG8SIo7KKU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39484a30-8659-411f-bee7-7ed4be731d95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Correlated Features:\n",
            "AST    1.000000\n",
            "TOV    0.901265\n",
            "FGA    0.821520\n",
            "PTS    0.813430\n",
            "FGM    0.805378\n",
            "STL    0.788628\n",
            "MIN    0.785776\n",
            "FTM    0.759553\n",
            "Name: AST, dtype: float64\n",
            "Top 8 Correlated Features: Index(['TOV', 'FGA', 'PTS', 'FGM', 'STL', 'MIN', 'FTM', 'FTA'], dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-265592d41c66>:10: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  correlations = all_players_df.corr()[target_variable].abs().sort_values(ascending=False)\n",
            "<ipython-input-4-265592d41c66>:23: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  correlations = all_players_df.corr()['AST'].abs().sort_values(ascending=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the 1st Iteration of the Model\n",
        "After finding the top 8 correlated features, we now knew what to target in our model. This was the most complicated portion of our process. We did not know whether we wanted to use a simple pass-forward Neural Network, or use some other sort of Machine Learning Algorithm. Eventually, we compared Random Forest Classification, a simple forward-feeding CNN, and a LSTM-Based RNN. We found that of the 3, the RNN had by far the most efficacy in reducing loss (MSE) and variance (R-Squared) (most likely due to the complexity of the model)."
      ],
      "metadata": {
        "id": "65v9mBy0YkiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PowerTransformer, PolynomialFeatures, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Constants\n",
        "FILE_PATH = '/content/all_players_career_stats_2013_2023.csv'\n",
        "FEATURES = ['FG3A', 'FGA', 'FTA', 'STL', 'TOV', 'PTS']\n",
        "TARGET = 'AST'\n",
        "SEED = 42\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Load data\n",
        "def load_data(file_path):\n",
        "    return pd.read_csv('/content/all_players_career_stats_2018_2023.csv')\n",
        "\n",
        "# Preprocess data\n",
        "def preprocess_data(data):\n",
        "    # Feature engineering\n",
        "    data['PTS'] = data['PTS'] / data['GP']\n",
        "    data = data.dropna(subset=FEATURES + [TARGET])\n",
        "    api_data_array = winsorize(data[FEATURES].values, limits=[0.01, 0.01], axis=0)\n",
        "    data[FEATURES] = pd.DataFrame(api_data_array, columns=FEATURES)\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    X_poly = poly.fit_transform(data[FEATURES])\n",
        "    poly_feature_names = poly.get_feature_names_out(FEATURES)\n",
        "    data_poly = pd.DataFrame(X_poly, columns=poly_feature_names)\n",
        "    power_transformer = PowerTransformer()\n",
        "    X_power = power_transformer.fit_transform(data[FEATURES])\n",
        "    data_power = pd.DataFrame(X_power, columns=FEATURES)\n",
        "    data = pd.concat([data, data_poly, data_power], axis=1)\n",
        "\n",
        "    # Prepare data\n",
        "    exclude_columns = [col for col in data.columns if col not in (FEATURES + [TARGET])]\n",
        "    X = data.drop(columns=exclude_columns)\n",
        "    y = data[TARGET].values\n",
        "\n",
        "    # Standardization using Min-Max Scaling\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return train_test_split(X_scaled, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# Create RNN model\n",
        "def create_rnn_model(input_shape):\n",
        "    model = keras.Sequential([\n",
        "        layers.LSTM(64, activation='relu', input_shape=(None, input_shape)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train RNN model\n",
        "def train_rnn_model(model, X_train, y_train, epochs=1000, batch_size=32, callbacks=None):\n",
        "    # Early stopping callback\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "\n",
        "    # Combine user-provided callbacks with early stopping\n",
        "    all_callbacks = [early_stopping] if callbacks is None else [early_stopping] + callbacks\n",
        "\n",
        "    # Reshape input for sequence modeling\n",
        "    X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "\n",
        "    # Train the model with combined callbacks\n",
        "    model.fit(\n",
        "        X_train_reshaped, y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=1,\n",
        "        validation_split=0.2,\n",
        "        callbacks=all_callbacks\n",
        "    )\n",
        "\n",
        "# Evaluate RNN model\n",
        "def evaluate_rnn_model(model, X_test, y_test):\n",
        "    # Reshape input for sequence modeling\n",
        "    X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "    rnn_pred = model.predict(X_test_reshaped)\n",
        "    rnn_mse = mean_squared_error(y_test, rnn_pred)\n",
        "    rnn_rmse = np.sqrt(rnn_mse)\n",
        "    rnn_mae = mean_absolute_error(y_test, rnn_pred)\n",
        "    rnn_r2 = r2_score(y_test, rnn_pred)\n",
        "    return rnn_pred, rnn_mse, rnn_rmse, rnn_mae, rnn_r2\n",
        "\n",
        "# Plot results\n",
        "def plot_results_rnn(y_true, y_pred, residual):\n",
        "    # Scatter Plot for RNN Predictions\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(y_true, y_pred.flatten(), alpha=0.5)\n",
        "    plt.title('RNN Predictions')\n",
        "    plt.xlabel('True Values')\n",
        "    plt.ylabel('Predicted Values')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Residual Plot for RNN\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.scatter(y_pred.flatten(), residual, alpha=0.5)\n",
        "    plt.title('Residual Plot - RNN')\n",
        "    plt.xlabel('Predicted Values')\n",
        "    plt.ylabel('Residuals')\n",
        "    plt.axhline(0, color='red', linestyle='--', linewidth=2)\n",
        "    plt.show()\n",
        "\n",
        "    # Distribution of Predictions for RNN\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(y_pred.flatten(), bins=30, alpha=0.5, label='RNN Predictions')\n",
        "    plt.hist(y_true, bins=30, alpha=0.5, label='True Values')\n",
        "    plt.title('Distribution of Predictions - RNN')\n",
        "    plt.xlabel('Values')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    api_data = load_data(FILE_PATH)\n",
        "    X_train, X_test, y_train, y_test = preprocess_data(api_data)\n",
        "\n",
        "    # Apply Isolation Forest to identify and potentially remove outliers from the training data\n",
        "    iso_forest = IsolationForest(contamination=0.05, random_state=SEED)\n",
        "    outlier_labels = iso_forest.fit_predict(X_train)\n",
        "    outlier_indices = np.where(outlier_labels == -1)[0]\n",
        "    X_train_no_outliers = np.delete(X_train, outlier_indices, axis=0)\n",
        "    y_train_no_outliers = np.delete(y_train, outlier_indices)\n",
        "\n",
        "    # Train the RNN model with outliers\n",
        "    rnn_model_with_outliers = create_rnn_model(X_train.shape[1])\n",
        "    train_rnn_model(rnn_model_with_outliers, X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the test set with outliers\n",
        "    rnn_pred_with_outliers, rnn_mse_with_outliers, rnn_rmse_with_outliers, rnn_mae_with_outliers, rnn_r2_with_outliers = evaluate_rnn_model(rnn_model_with_outliers, X_test, y_test)\n",
        "\n",
        "    # Print or use the evaluation metrics for the model with outliers\n",
        "    print(\"\\nRNN Model Metrics with Outliers:\")\n",
        "    print(\"MSE:\", rnn_mse_with_outliers)\n",
        "    print(\"RMSE:\", rnn_rmse_with_outliers)\n",
        "    print(\"MAE:\", rnn_mae_with_outliers)\n",
        "    print(\"R-squared:\", rnn_r2_with_outliers)\n",
        "\n",
        "    # Plot results for the model with outliers\n",
        "    plot_results_rnn(y_test, rnn_pred_with_outliers.flatten(), y_test - rnn_pred_with_outliers.flatten())\n",
        "\n",
        "    # Train the RNN model without outliers\n",
        "    rnn_model_no_outliers = create_rnn_model(X_train_no_outliers.shape[1])\n",
        "    train_rnn_model(rnn_model_no_outliers, X_train_no_outliers, y_train_no_outliers)\n",
        "\n",
        "    # Evaluate the model on the test set without outliers\n",
        "    rnn_pred_no_outliers, rnn_mse_no_outliers, rnn_rmse_no_outliers, rnn_mae_no_outliers, rnn_r2_no_outliers = evaluate_rnn_model(rnn_model_no_outliers, X_test, y_test)\n",
        "\n",
        "    # Print or use the evaluation metrics for the model without outliers\n",
        "    print(\"\\nRNN Model Metrics without Outliers:\")\n",
        "    print(\"MSE:\", rnn_mse_no_outliers)\n",
        "    print(\"RMSE:\", rnn_rmse_no_outliers)\n",
        "    print(\"MAE:\", rnn_mae_no_outliers)\n",
        "    print(\"R-squared:\", rnn_r2_no_outliers)\n",
        "\n",
        "    # Plot results for the model without outliers\n",
        "    plot_results_rnn(y_test, rnn_pred_no_outliers.flatten(), y_test - rnn_pred_no_outliers.flatten())\n",
        "\n",
        "    # RNN Model Summary\n",
        "    rnn_model_with_outliers.summary()\n",
        "    rnn_model_no_outliers.summary()"
      ],
      "metadata": {
        "id": "ED6cjwoTadQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b026eec4-6fe1-4608-fda6-bfefbb462038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "72/72 [==============================] - 3s 9ms/step - loss: 19383.4980 - mean_squared_error: 19383.4980 - val_loss: 18018.9824 - val_mean_squared_error: 18018.9824\n",
            "Epoch 2/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 12872.5977 - mean_squared_error: 12872.5977 - val_loss: 5845.6450 - val_mean_squared_error: 5845.6450\n",
            "Epoch 3/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 4139.4854 - mean_squared_error: 4139.4854 - val_loss: 3068.8762 - val_mean_squared_error: 3068.8760\n",
            "Epoch 4/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 3327.7322 - mean_squared_error: 3327.7322 - val_loss: 2802.6580 - val_mean_squared_error: 2802.6580\n",
            "Epoch 5/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 2988.2874 - mean_squared_error: 2988.2874 - val_loss: 2552.2605 - val_mean_squared_error: 2552.2605\n",
            "Epoch 6/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 2735.2881 - mean_squared_error: 2735.2881 - val_loss: 2317.9417 - val_mean_squared_error: 2317.9417\n",
            "Epoch 7/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 2530.5166 - mean_squared_error: 2530.5166 - val_loss: 2135.8506 - val_mean_squared_error: 2135.8506\n",
            "Epoch 8/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 2400.9614 - mean_squared_error: 2400.9614 - val_loss: 1992.6777 - val_mean_squared_error: 1992.6777\n",
            "Epoch 9/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 2234.1501 - mean_squared_error: 2234.1501 - val_loss: 1868.2151 - val_mean_squared_error: 1868.2151\n",
            "Epoch 10/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 2034.9701 - mean_squared_error: 2034.9701 - val_loss: 1751.2703 - val_mean_squared_error: 1751.2703\n",
            "Epoch 11/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 1999.3816 - mean_squared_error: 1999.3816 - val_loss: 1639.4711 - val_mean_squared_error: 1639.4711\n",
            "Epoch 12/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 1849.4589 - mean_squared_error: 1849.4589 - val_loss: 1500.1626 - val_mean_squared_error: 1500.1626\n",
            "Epoch 13/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 1729.9650 - mean_squared_error: 1729.9650 - val_loss: 1391.0399 - val_mean_squared_error: 1391.0399\n",
            "Epoch 14/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 1620.6459 - mean_squared_error: 1620.6459 - val_loss: 1296.2374 - val_mean_squared_error: 1296.2374\n",
            "Epoch 15/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 1495.9386 - mean_squared_error: 1495.9386 - val_loss: 1164.3844 - val_mean_squared_error: 1164.3844\n",
            "Epoch 16/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 1364.5999 - mean_squared_error: 1364.5999 - val_loss: 1058.2274 - val_mean_squared_error: 1058.2274\n",
            "Epoch 17/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 1302.3282 - mean_squared_error: 1302.3282 - val_loss: 969.3157 - val_mean_squared_error: 969.3157\n",
            "Epoch 18/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1190.4596 - mean_squared_error: 1190.4596 - val_loss: 876.4124 - val_mean_squared_error: 876.4124\n",
            "Epoch 19/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1133.8274 - mean_squared_error: 1133.8274 - val_loss: 810.8881 - val_mean_squared_error: 810.8881\n",
            "Epoch 20/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1046.6863 - mean_squared_error: 1046.6863 - val_loss: 736.2094 - val_mean_squared_error: 736.2094\n",
            "Epoch 21/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1025.5389 - mean_squared_error: 1025.5389 - val_loss: 672.2377 - val_mean_squared_error: 672.2378\n",
            "Epoch 22/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 905.8918 - mean_squared_error: 905.8918 - val_loss: 626.0954 - val_mean_squared_error: 626.0954\n",
            "Epoch 23/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 865.1066 - mean_squared_error: 865.1066 - val_loss: 572.1425 - val_mean_squared_error: 572.1425\n",
            "Epoch 24/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 813.4172 - mean_squared_error: 813.4172 - val_loss: 532.2524 - val_mean_squared_error: 532.2524\n",
            "Epoch 25/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 767.8641 - mean_squared_error: 767.8641 - val_loss: 505.1092 - val_mean_squared_error: 505.1092\n",
            "Epoch 26/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 693.9670 - mean_squared_error: 693.9670 - val_loss: 445.9732 - val_mean_squared_error: 445.9732\n",
            "Epoch 27/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 698.5887 - mean_squared_error: 698.5887 - val_loss: 424.1397 - val_mean_squared_error: 424.1397\n",
            "Epoch 28/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 675.3981 - mean_squared_error: 675.3981 - val_loss: 388.8900 - val_mean_squared_error: 388.8900\n",
            "Epoch 29/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 624.8428 - mean_squared_error: 624.8428 - val_loss: 391.1874 - val_mean_squared_error: 391.1874\n",
            "Epoch 30/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 595.4481 - mean_squared_error: 595.4481 - val_loss: 396.3778 - val_mean_squared_error: 396.3778\n",
            "Epoch 31/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 577.2121 - mean_squared_error: 577.2121 - val_loss: 308.0907 - val_mean_squared_error: 308.0907\n",
            "Epoch 32/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 519.3557 - mean_squared_error: 519.3557 - val_loss: 283.7367 - val_mean_squared_error: 283.7367\n",
            "Epoch 33/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 511.1017 - mean_squared_error: 511.1017 - val_loss: 265.1060 - val_mean_squared_error: 265.1060\n",
            "Epoch 34/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 504.9928 - mean_squared_error: 504.9928 - val_loss: 256.0042 - val_mean_squared_error: 256.0042\n",
            "Epoch 35/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 484.8353 - mean_squared_error: 484.8353 - val_loss: 237.1985 - val_mean_squared_error: 237.1985\n",
            "Epoch 36/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 454.5778 - mean_squared_error: 454.5778 - val_loss: 244.4427 - val_mean_squared_error: 244.4427\n",
            "Epoch 37/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 437.9159 - mean_squared_error: 437.9159 - val_loss: 208.2765 - val_mean_squared_error: 208.2765\n",
            "Epoch 38/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 398.3002 - mean_squared_error: 398.3002 - val_loss: 203.7304 - val_mean_squared_error: 203.7304\n",
            "Epoch 39/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 432.9813 - mean_squared_error: 432.9813 - val_loss: 182.7699 - val_mean_squared_error: 182.7699\n",
            "Epoch 40/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 418.8990 - mean_squared_error: 418.8990 - val_loss: 183.2166 - val_mean_squared_error: 183.2166\n",
            "Epoch 41/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 383.0511 - mean_squared_error: 383.0511 - val_loss: 170.0145 - val_mean_squared_error: 170.0145\n",
            "Epoch 42/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 399.5933 - mean_squared_error: 399.5933 - val_loss: 154.6030 - val_mean_squared_error: 154.6030\n",
            "Epoch 43/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 378.3743 - mean_squared_error: 378.3743 - val_loss: 143.6921 - val_mean_squared_error: 143.6921\n",
            "Epoch 44/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 377.8945 - mean_squared_error: 377.8945 - val_loss: 148.5593 - val_mean_squared_error: 148.5593\n",
            "Epoch 45/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 354.3197 - mean_squared_error: 354.3197 - val_loss: 135.3468 - val_mean_squared_error: 135.3468\n",
            "Epoch 46/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 314.1476 - mean_squared_error: 314.1476 - val_loss: 124.3240 - val_mean_squared_error: 124.3240\n",
            "Epoch 47/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 308.2499 - mean_squared_error: 308.2499 - val_loss: 117.5798 - val_mean_squared_error: 117.5798\n",
            "Epoch 48/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 328.5525 - mean_squared_error: 328.5525 - val_loss: 116.6649 - val_mean_squared_error: 116.6649\n",
            "Epoch 49/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 314.9391 - mean_squared_error: 314.9391 - val_loss: 104.7278 - val_mean_squared_error: 104.7278\n",
            "Epoch 50/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 301.9722 - mean_squared_error: 301.9722 - val_loss: 96.1797 - val_mean_squared_error: 96.1797\n",
            "Epoch 51/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 290.6202 - mean_squared_error: 290.6202 - val_loss: 92.0391 - val_mean_squared_error: 92.0391\n",
            "Epoch 52/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 296.8791 - mean_squared_error: 296.8791 - val_loss: 102.6163 - val_mean_squared_error: 102.6163\n",
            "Epoch 53/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 294.0534 - mean_squared_error: 294.0534 - val_loss: 106.1302 - val_mean_squared_error: 106.1302\n",
            "Epoch 54/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 269.4092 - mean_squared_error: 269.4092 - val_loss: 87.0480 - val_mean_squared_error: 87.0480\n",
            "Epoch 55/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 273.8258 - mean_squared_error: 273.8258 - val_loss: 81.2354 - val_mean_squared_error: 81.2354\n",
            "Epoch 56/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 249.1275 - mean_squared_error: 249.1275 - val_loss: 80.6794 - val_mean_squared_error: 80.6794\n",
            "Epoch 57/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 273.2429 - mean_squared_error: 273.2429 - val_loss: 68.8493 - val_mean_squared_error: 68.8493\n",
            "Epoch 58/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 253.8070 - mean_squared_error: 253.8070 - val_loss: 78.3836 - val_mean_squared_error: 78.3836\n",
            "Epoch 59/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 281.2184 - mean_squared_error: 281.2184 - val_loss: 63.6059 - val_mean_squared_error: 63.6059\n",
            "Epoch 60/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 288.5315 - mean_squared_error: 288.5315 - val_loss: 66.3823 - val_mean_squared_error: 66.3823\n",
            "Epoch 61/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 261.1001 - mean_squared_error: 261.1001 - val_loss: 69.5026 - val_mean_squared_error: 69.5026\n",
            "Epoch 62/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 265.4975 - mean_squared_error: 265.4975 - val_loss: 62.6788 - val_mean_squared_error: 62.6788\n",
            "Epoch 63/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 253.3876 - mean_squared_error: 253.3876 - val_loss: 68.2314 - val_mean_squared_error: 68.2314\n",
            "Epoch 64/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 254.4290 - mean_squared_error: 254.4290 - val_loss: 55.3382 - val_mean_squared_error: 55.3382\n",
            "Epoch 65/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 238.3994 - mean_squared_error: 238.3994 - val_loss: 59.3992 - val_mean_squared_error: 59.3992\n",
            "Epoch 66/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 236.6026 - mean_squared_error: 236.6026 - val_loss: 60.8002 - val_mean_squared_error: 60.8002\n",
            "Epoch 67/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 266.1242 - mean_squared_error: 266.1242 - val_loss: 60.7413 - val_mean_squared_error: 60.7413\n",
            "Epoch 68/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 240.6402 - mean_squared_error: 240.6402 - val_loss: 57.1031 - val_mean_squared_error: 57.1031\n",
            "Epoch 69/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 245.3616 - mean_squared_error: 245.3616 - val_loss: 60.0777 - val_mean_squared_error: 60.0777\n",
            "Epoch 70/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 232.2629 - mean_squared_error: 232.2629 - val_loss: 53.1304 - val_mean_squared_error: 53.1304\n",
            "Epoch 71/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 234.9366 - mean_squared_error: 234.9366 - val_loss: 47.7389 - val_mean_squared_error: 47.7389\n",
            "Epoch 72/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 237.2571 - mean_squared_error: 237.2571 - val_loss: 51.7567 - val_mean_squared_error: 51.7567\n",
            "Epoch 73/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 244.9829 - mean_squared_error: 244.9829 - val_loss: 49.3112 - val_mean_squared_error: 49.3112\n",
            "Epoch 74/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 255.4929 - mean_squared_error: 255.4929 - val_loss: 50.7935 - val_mean_squared_error: 50.7935\n",
            "Epoch 75/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 240.1357 - mean_squared_error: 240.1357 - val_loss: 49.9395 - val_mean_squared_error: 49.9395\n",
            "Epoch 76/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 223.7055 - mean_squared_error: 223.7055 - val_loss: 59.5621 - val_mean_squared_error: 59.5621\n",
            "Epoch 77/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 228.3804 - mean_squared_error: 228.3804 - val_loss: 54.8654 - val_mean_squared_error: 54.8654\n",
            "Epoch 78/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 259.4551 - mean_squared_error: 259.4551 - val_loss: 55.8534 - val_mean_squared_error: 55.8534\n",
            "Epoch 79/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 247.8813 - mean_squared_error: 247.8813 - val_loss: 57.9243 - val_mean_squared_error: 57.9243\n",
            "Epoch 80/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 236.6126 - mean_squared_error: 236.6126 - val_loss: 45.8496 - val_mean_squared_error: 45.8496\n",
            "Epoch 81/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 235.1781 - mean_squared_error: 235.1781 - val_loss: 49.3628 - val_mean_squared_error: 49.3628\n",
            "Epoch 82/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 249.5060 - mean_squared_error: 249.5060 - val_loss: 40.4915 - val_mean_squared_error: 40.4915\n",
            "Epoch 83/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 203.8257 - mean_squared_error: 203.8257 - val_loss: 61.7482 - val_mean_squared_error: 61.7482\n",
            "Epoch 84/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 211.5718 - mean_squared_error: 211.5718 - val_loss: 51.9542 - val_mean_squared_error: 51.9542\n",
            "Epoch 85/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 205.6981 - mean_squared_error: 205.6981 - val_loss: 41.2404 - val_mean_squared_error: 41.2404\n",
            "Epoch 86/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 208.2427 - mean_squared_error: 208.2427 - val_loss: 43.9332 - val_mean_squared_error: 43.9332\n",
            "Epoch 87/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 219.1951 - mean_squared_error: 219.1951 - val_loss: 40.3826 - val_mean_squared_error: 40.3826\n",
            "Epoch 88/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 208.5636 - mean_squared_error: 208.5636 - val_loss: 39.6321 - val_mean_squared_error: 39.6321\n",
            "Epoch 89/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 185.1045 - mean_squared_error: 185.1045 - val_loss: 45.0284 - val_mean_squared_error: 45.0284\n",
            "Epoch 90/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 248.0442 - mean_squared_error: 248.0442 - val_loss: 61.2382 - val_mean_squared_error: 61.2382\n",
            "Epoch 91/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 251.2030 - mean_squared_error: 251.2030 - val_loss: 37.6303 - val_mean_squared_error: 37.6303\n",
            "Epoch 92/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 203.2498 - mean_squared_error: 203.2498 - val_loss: 42.6787 - val_mean_squared_error: 42.6787\n",
            "Epoch 93/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 210.5197 - mean_squared_error: 210.5197 - val_loss: 36.7450 - val_mean_squared_error: 36.7450\n",
            "Epoch 94/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 222.8848 - mean_squared_error: 222.8848 - val_loss: 49.2151 - val_mean_squared_error: 49.2151\n",
            "Epoch 95/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 219.3089 - mean_squared_error: 219.3089 - val_loss: 53.8666 - val_mean_squared_error: 53.8666\n",
            "Epoch 96/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 203.9343 - mean_squared_error: 203.9343 - val_loss: 49.7195 - val_mean_squared_error: 49.7195\n",
            "Epoch 97/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 194.7747 - mean_squared_error: 194.7747 - val_loss: 40.7459 - val_mean_squared_error: 40.7459\n",
            "Epoch 98/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 194.7952 - mean_squared_error: 194.7952 - val_loss: 54.7652 - val_mean_squared_error: 54.7652\n",
            "Epoch 99/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 212.3333 - mean_squared_error: 212.3333 - val_loss: 59.3009 - val_mean_squared_error: 59.3009\n",
            "Epoch 100/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 197.4556 - mean_squared_error: 197.4556 - val_loss: 39.5460 - val_mean_squared_error: 39.5460\n",
            "Epoch 101/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 208.1544 - mean_squared_error: 208.1544 - val_loss: 50.3225 - val_mean_squared_error: 50.3225\n",
            "Epoch 102/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 210.6120 - mean_squared_error: 210.6120 - val_loss: 47.5102 - val_mean_squared_error: 47.5102\n",
            "Epoch 103/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 213.8342 - mean_squared_error: 213.8342 - val_loss: 41.8384 - val_mean_squared_error: 41.8384\n",
            "Epoch 104/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 215.8545 - mean_squared_error: 215.8545 - val_loss: 35.9767 - val_mean_squared_error: 35.9767\n",
            "Epoch 105/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 197.2729 - mean_squared_error: 197.2729 - val_loss: 51.8987 - val_mean_squared_error: 51.8987\n",
            "Epoch 106/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 199.6257 - mean_squared_error: 199.6257 - val_loss: 38.9704 - val_mean_squared_error: 38.9704\n",
            "Epoch 107/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 195.1098 - mean_squared_error: 195.1098 - val_loss: 39.4418 - val_mean_squared_error: 39.4418\n",
            "Epoch 108/1000\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 188.8276 - mean_squared_error: 188.8276 - val_loss: 56.5470 - val_mean_squared_error: 56.5470\n",
            "Epoch 109/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 184.0903 - mean_squared_error: 184.0903 - val_loss: 49.1052 - val_mean_squared_error: 49.1052\n",
            "Epoch 110/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 202.3800 - mean_squared_error: 202.3800 - val_loss: 49.2352 - val_mean_squared_error: 49.2352\n",
            "Epoch 111/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 191.6983 - mean_squared_error: 191.6983 - val_loss: 39.9351 - val_mean_squared_error: 39.9351\n",
            "Epoch 112/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 208.0865 - mean_squared_error: 208.0865 - val_loss: 58.5327 - val_mean_squared_error: 58.5327\n",
            "Epoch 113/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 209.4943 - mean_squared_error: 209.4943 - val_loss: 37.5028 - val_mean_squared_error: 37.5028\n",
            "Epoch 114/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 222.9101 - mean_squared_error: 222.9101 - val_loss: 43.5381 - val_mean_squared_error: 43.5381\n",
            "Epoch 115/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 215.3468 - mean_squared_error: 215.3468 - val_loss: 45.8347 - val_mean_squared_error: 45.8347\n",
            "Epoch 116/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 203.9703 - mean_squared_error: 203.9703 - val_loss: 40.4360 - val_mean_squared_error: 40.4360\n",
            "Epoch 117/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 177.5125 - mean_squared_error: 177.5125 - val_loss: 41.7931 - val_mean_squared_error: 41.7931\n",
            "Epoch 118/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 204.6640 - mean_squared_error: 204.6640 - val_loss: 42.6899 - val_mean_squared_error: 42.6899\n",
            "Epoch 119/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 179.7899 - mean_squared_error: 179.7899 - val_loss: 37.0852 - val_mean_squared_error: 37.0852\n",
            "Epoch 120/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 181.4760 - mean_squared_error: 181.4760 - val_loss: 37.5438 - val_mean_squared_error: 37.5438\n",
            "Epoch 121/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 170.6980 - mean_squared_error: 170.6980 - val_loss: 36.4067 - val_mean_squared_error: 36.4067\n",
            "Epoch 122/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 202.8986 - mean_squared_error: 202.8986 - val_loss: 42.7341 - val_mean_squared_error: 42.7341\n",
            "Epoch 123/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 225.2066 - mean_squared_error: 225.2066 - val_loss: 66.5655 - val_mean_squared_error: 66.5655\n",
            "Epoch 124/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 208.5435 - mean_squared_error: 208.5435 - val_loss: 38.0308 - val_mean_squared_error: 38.0308\n",
            "Epoch 125/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 174.0819 - mean_squared_error: 174.0819 - val_loss: 29.0687 - val_mean_squared_error: 29.0687\n",
            "Epoch 126/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 203.8236 - mean_squared_error: 203.8236 - val_loss: 42.9221 - val_mean_squared_error: 42.9221\n",
            "Epoch 127/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 213.4933 - mean_squared_error: 213.4933 - val_loss: 37.9468 - val_mean_squared_error: 37.9468\n",
            "Epoch 128/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 195.3502 - mean_squared_error: 195.3502 - val_loss: 48.1186 - val_mean_squared_error: 48.1186\n",
            "Epoch 129/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 191.2306 - mean_squared_error: 191.2306 - val_loss: 35.6167 - val_mean_squared_error: 35.6167\n",
            "Epoch 130/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 223.6552 - mean_squared_error: 223.6552 - val_loss: 30.4049 - val_mean_squared_error: 30.4049\n",
            "Epoch 131/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 214.8257 - mean_squared_error: 214.8257 - val_loss: 34.7898 - val_mean_squared_error: 34.7898\n",
            "Epoch 132/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 190.8521 - mean_squared_error: 190.8521 - val_loss: 38.5866 - val_mean_squared_error: 38.5866\n",
            "Epoch 133/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 193.8451 - mean_squared_error: 193.8451 - val_loss: 48.3349 - val_mean_squared_error: 48.3349\n",
            "Epoch 134/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 187.1990 - mean_squared_error: 187.1990 - val_loss: 36.4008 - val_mean_squared_error: 36.4008\n",
            "Epoch 135/1000\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 208.0459 - mean_squared_error: 208.0459 - val_loss: 54.9782 - val_mean_squared_error: 54.9782\n",
            "Epoch 136/1000\n",
            "72/72 [==============================] - 1s 14ms/step - loss: 212.2958 - mean_squared_error: 212.2958 - val_loss: 57.0498 - val_mean_squared_error: 57.0498\n",
            "Epoch 137/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 201.7358 - mean_squared_error: 201.7358 - val_loss: 46.3096 - val_mean_squared_error: 46.3096\n",
            "Epoch 138/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 180.0502 - mean_squared_error: 180.0502 - val_loss: 50.9947 - val_mean_squared_error: 50.9947\n",
            "Epoch 139/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 181.4939 - mean_squared_error: 181.4939 - val_loss: 31.1235 - val_mean_squared_error: 31.1235\n",
            "Epoch 140/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 175.2544 - mean_squared_error: 175.2544 - val_loss: 29.9123 - val_mean_squared_error: 29.9123\n",
            "Epoch 141/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 194.7773 - mean_squared_error: 194.7773 - val_loss: 41.5562 - val_mean_squared_error: 41.5562\n",
            "Epoch 142/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 196.3706 - mean_squared_error: 196.3706 - val_loss: 51.4105 - val_mean_squared_error: 51.4105\n",
            "Epoch 143/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 198.9075 - mean_squared_error: 198.9075 - val_loss: 29.3784 - val_mean_squared_error: 29.3784\n",
            "Epoch 144/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 198.6135 - mean_squared_error: 198.6135 - val_loss: 31.1902 - val_mean_squared_error: 31.1902\n",
            "Epoch 145/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 171.9073 - mean_squared_error: 171.9073 - val_loss: 45.6116 - val_mean_squared_error: 45.6116\n",
            "Epoch 146/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 167.2312 - mean_squared_error: 167.2312 - val_loss: 30.7805 - val_mean_squared_error: 30.7805\n",
            "Epoch 147/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 176.5710 - mean_squared_error: 176.5710 - val_loss: 28.8785 - val_mean_squared_error: 28.8785\n",
            "Epoch 148/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 175.7803 - mean_squared_error: 175.7803 - val_loss: 27.6506 - val_mean_squared_error: 27.6506\n",
            "Epoch 149/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 199.3279 - mean_squared_error: 199.3279 - val_loss: 38.2907 - val_mean_squared_error: 38.2907\n",
            "Epoch 150/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 172.1237 - mean_squared_error: 172.1237 - val_loss: 47.0707 - val_mean_squared_error: 47.0707\n",
            "Epoch 151/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 211.8831 - mean_squared_error: 211.8831 - val_loss: 28.3956 - val_mean_squared_error: 28.3956\n",
            "Epoch 152/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 189.4244 - mean_squared_error: 189.4244 - val_loss: 36.0200 - val_mean_squared_error: 36.0200\n",
            "Epoch 153/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 189.7829 - mean_squared_error: 189.7829 - val_loss: 38.7490 - val_mean_squared_error: 38.7490\n",
            "Epoch 154/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 206.4376 - mean_squared_error: 206.4376 - val_loss: 46.5679 - val_mean_squared_error: 46.5679\n",
            "Epoch 155/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 188.8249 - mean_squared_error: 188.8249 - val_loss: 27.7981 - val_mean_squared_error: 27.7981\n",
            "Epoch 156/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 166.9277 - mean_squared_error: 166.9277 - val_loss: 25.8641 - val_mean_squared_error: 25.8641\n",
            "Epoch 157/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 182.0265 - mean_squared_error: 182.0265 - val_loss: 45.5980 - val_mean_squared_error: 45.5980\n",
            "Epoch 158/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 164.8107 - mean_squared_error: 164.8107 - val_loss: 26.7678 - val_mean_squared_error: 26.7678\n",
            "Epoch 159/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 198.9804 - mean_squared_error: 198.9804 - val_loss: 33.0768 - val_mean_squared_error: 33.0768\n",
            "Epoch 160/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 166.4261 - mean_squared_error: 166.4261 - val_loss: 26.0644 - val_mean_squared_error: 26.0644\n",
            "Epoch 161/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 166.8423 - mean_squared_error: 166.8423 - val_loss: 66.1646 - val_mean_squared_error: 66.1646\n",
            "Epoch 162/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 214.5404 - mean_squared_error: 214.5404 - val_loss: 21.2342 - val_mean_squared_error: 21.2342\n",
            "Epoch 163/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 213.1617 - mean_squared_error: 213.1617 - val_loss: 27.2348 - val_mean_squared_error: 27.2348\n",
            "Epoch 164/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 160.6485 - mean_squared_error: 160.6485 - val_loss: 24.0086 - val_mean_squared_error: 24.0086\n",
            "Epoch 165/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 168.8497 - mean_squared_error: 168.8497 - val_loss: 29.5889 - val_mean_squared_error: 29.5889\n",
            "Epoch 166/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 169.0560 - mean_squared_error: 169.0560 - val_loss: 26.8602 - val_mean_squared_error: 26.8602\n",
            "Epoch 167/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 178.0345 - mean_squared_error: 178.0345 - val_loss: 42.3642 - val_mean_squared_error: 42.3642\n",
            "Epoch 168/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 172.6202 - mean_squared_error: 172.6202 - val_loss: 43.0775 - val_mean_squared_error: 43.0775\n",
            "Epoch 169/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 173.8893 - mean_squared_error: 173.8893 - val_loss: 35.2370 - val_mean_squared_error: 35.2370\n",
            "Epoch 170/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 180.5345 - mean_squared_error: 180.5345 - val_loss: 23.4398 - val_mean_squared_error: 23.4398\n",
            "Epoch 171/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 164.3073 - mean_squared_error: 164.3073 - val_loss: 28.4762 - val_mean_squared_error: 28.4762\n",
            "Epoch 172/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 174.1197 - mean_squared_error: 174.1197 - val_loss: 27.7920 - val_mean_squared_error: 27.7920\n",
            "Epoch 173/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 180.8886 - mean_squared_error: 180.8886 - val_loss: 28.2309 - val_mean_squared_error: 28.2309\n",
            "Epoch 174/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 160.3322 - mean_squared_error: 160.3322 - val_loss: 26.5357 - val_mean_squared_error: 26.5357\n",
            "Epoch 175/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 178.2475 - mean_squared_error: 178.2475 - val_loss: 51.0142 - val_mean_squared_error: 51.0142\n",
            "Epoch 176/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 173.6371 - mean_squared_error: 173.6371 - val_loss: 26.1843 - val_mean_squared_error: 26.1843\n",
            "Epoch 177/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 191.3766 - mean_squared_error: 191.3766 - val_loss: 37.5823 - val_mean_squared_error: 37.5823\n",
            "Epoch 178/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 154.5777 - mean_squared_error: 154.5777 - val_loss: 27.5170 - val_mean_squared_error: 27.5170\n",
            "Epoch 179/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 158.5323 - mean_squared_error: 158.5323 - val_loss: 30.5318 - val_mean_squared_error: 30.5318\n",
            "Epoch 180/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 151.8472 - mean_squared_error: 151.8472 - val_loss: 49.2651 - val_mean_squared_error: 49.2651\n",
            "Epoch 181/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 198.3809 - mean_squared_error: 198.3809 - val_loss: 30.2336 - val_mean_squared_error: 30.2336\n",
            "Epoch 182/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 176.5718 - mean_squared_error: 176.5718 - val_loss: 28.3007 - val_mean_squared_error: 28.3007\n",
            "Epoch 183/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 160.0476 - mean_squared_error: 160.0476 - val_loss: 22.1517 - val_mean_squared_error: 22.1517\n",
            "Epoch 184/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 156.5662 - mean_squared_error: 156.5662 - val_loss: 25.4477 - val_mean_squared_error: 25.4477\n",
            "Epoch 185/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 169.4515 - mean_squared_error: 169.4515 - val_loss: 43.7022 - val_mean_squared_error: 43.7022\n",
            "Epoch 186/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 166.9929 - mean_squared_error: 166.9929 - val_loss: 30.9896 - val_mean_squared_error: 30.9896\n",
            "Epoch 187/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 168.9966 - mean_squared_error: 168.9966 - val_loss: 36.1420 - val_mean_squared_error: 36.1420\n",
            "Epoch 188/1000\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 185.1386 - mean_squared_error: 185.1386 - val_loss: 27.4888 - val_mean_squared_error: 27.4888\n",
            "Epoch 189/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 171.3406 - mean_squared_error: 171.3406 - val_loss: 26.7705 - val_mean_squared_error: 26.7705\n",
            "Epoch 190/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 161.8461 - mean_squared_error: 161.8461 - val_loss: 21.2213 - val_mean_squared_error: 21.2213\n",
            "Epoch 191/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 175.2639 - mean_squared_error: 175.2639 - val_loss: 25.9670 - val_mean_squared_error: 25.9670\n",
            "Epoch 192/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 185.2594 - mean_squared_error: 185.2594 - val_loss: 34.9637 - val_mean_squared_error: 34.9637\n",
            "Epoch 193/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 157.8124 - mean_squared_error: 157.8124 - val_loss: 24.6162 - val_mean_squared_error: 24.6162\n",
            "Epoch 194/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 204.5466 - mean_squared_error: 204.5466 - val_loss: 25.2707 - val_mean_squared_error: 25.2707\n",
            "Epoch 195/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 162.0943 - mean_squared_error: 162.0943 - val_loss: 27.3579 - val_mean_squared_error: 27.3579\n",
            "Epoch 196/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 169.3979 - mean_squared_error: 169.3979 - val_loss: 32.6346 - val_mean_squared_error: 32.6346\n",
            "Epoch 197/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 180.5704 - mean_squared_error: 180.5704 - val_loss: 22.5309 - val_mean_squared_error: 22.5309\n",
            "Epoch 198/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 171.6613 - mean_squared_error: 171.6613 - val_loss: 36.6534 - val_mean_squared_error: 36.6534\n",
            "Epoch 199/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 172.0688 - mean_squared_error: 172.0688 - val_loss: 19.3216 - val_mean_squared_error: 19.3216\n",
            "Epoch 200/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 152.2342 - mean_squared_error: 152.2342 - val_loss: 24.2920 - val_mean_squared_error: 24.2920\n",
            "Epoch 201/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 170.3535 - mean_squared_error: 170.3535 - val_loss: 22.9488 - val_mean_squared_error: 22.9488\n",
            "Epoch 202/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 164.4608 - mean_squared_error: 164.4608 - val_loss: 21.6388 - val_mean_squared_error: 21.6388\n",
            "Epoch 203/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 183.3118 - mean_squared_error: 183.3118 - val_loss: 22.0023 - val_mean_squared_error: 22.0023\n",
            "Epoch 204/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 166.1859 - mean_squared_error: 166.1859 - val_loss: 28.7912 - val_mean_squared_error: 28.7912\n",
            "Epoch 205/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 159.3147 - mean_squared_error: 159.3147 - val_loss: 20.2909 - val_mean_squared_error: 20.2909\n",
            "Epoch 206/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 161.1770 - mean_squared_error: 161.1770 - val_loss: 33.5862 - val_mean_squared_error: 33.5862\n",
            "Epoch 207/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 150.6312 - mean_squared_error: 150.6312 - val_loss: 29.7678 - val_mean_squared_error: 29.7678\n",
            "Epoch 208/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 148.2965 - mean_squared_error: 148.2965 - val_loss: 23.2835 - val_mean_squared_error: 23.2835\n",
            "Epoch 209/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 144.9305 - mean_squared_error: 144.9305 - val_loss: 20.4436 - val_mean_squared_error: 20.4436\n",
            "Epoch 210/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 155.8861 - mean_squared_error: 155.8861 - val_loss: 24.0604 - val_mean_squared_error: 24.0604\n",
            "Epoch 211/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 155.6546 - mean_squared_error: 155.6546 - val_loss: 21.0447 - val_mean_squared_error: 21.0447\n",
            "Epoch 212/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 160.4530 - mean_squared_error: 160.4530 - val_loss: 18.3411 - val_mean_squared_error: 18.3411\n",
            "Epoch 213/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 157.8473 - mean_squared_error: 157.8473 - val_loss: 25.3783 - val_mean_squared_error: 25.3783\n",
            "Epoch 214/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 163.2020 - mean_squared_error: 163.2020 - val_loss: 18.5791 - val_mean_squared_error: 18.5791\n",
            "Epoch 215/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 145.2174 - mean_squared_error: 145.2174 - val_loss: 24.6332 - val_mean_squared_error: 24.6332\n",
            "Epoch 216/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 148.9111 - mean_squared_error: 148.9111 - val_loss: 21.9654 - val_mean_squared_error: 21.9654\n",
            "Epoch 217/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 142.8664 - mean_squared_error: 142.8664 - val_loss: 22.8282 - val_mean_squared_error: 22.8282\n",
            "Epoch 218/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 162.1755 - mean_squared_error: 162.1755 - val_loss: 18.3612 - val_mean_squared_error: 18.3612\n",
            "Epoch 219/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 166.3397 - mean_squared_error: 166.3397 - val_loss: 28.6637 - val_mean_squared_error: 28.6637\n",
            "Epoch 220/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 156.7192 - mean_squared_error: 156.7192 - val_loss: 30.6756 - val_mean_squared_error: 30.6756\n",
            "Epoch 221/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 156.8175 - mean_squared_error: 156.8175 - val_loss: 17.8490 - val_mean_squared_error: 17.8490\n",
            "Epoch 222/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 151.4202 - mean_squared_error: 151.4202 - val_loss: 19.5704 - val_mean_squared_error: 19.5704\n",
            "Epoch 223/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 139.8862 - mean_squared_error: 139.8862 - val_loss: 22.4054 - val_mean_squared_error: 22.4054\n",
            "Epoch 224/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 150.0776 - mean_squared_error: 150.0776 - val_loss: 15.3979 - val_mean_squared_error: 15.3979\n",
            "Epoch 225/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 152.9407 - mean_squared_error: 152.9407 - val_loss: 15.4977 - val_mean_squared_error: 15.4977\n",
            "Epoch 226/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 136.7664 - mean_squared_error: 136.7664 - val_loss: 19.8252 - val_mean_squared_error: 19.8252\n",
            "Epoch 227/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 161.3499 - mean_squared_error: 161.3499 - val_loss: 26.3389 - val_mean_squared_error: 26.3389\n",
            "Epoch 228/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 148.5533 - mean_squared_error: 148.5533 - val_loss: 20.4941 - val_mean_squared_error: 20.4941\n",
            "Epoch 229/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 162.9958 - mean_squared_error: 162.9958 - val_loss: 24.8518 - val_mean_squared_error: 24.8518\n",
            "Epoch 230/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 154.0797 - mean_squared_error: 154.0797 - val_loss: 20.6349 - val_mean_squared_error: 20.6349\n",
            "Epoch 231/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 140.7832 - mean_squared_error: 140.7832 - val_loss: 41.2674 - val_mean_squared_error: 41.2674\n",
            "Epoch 232/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 155.8498 - mean_squared_error: 155.8498 - val_loss: 38.8902 - val_mean_squared_error: 38.8902\n",
            "Epoch 233/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 163.9041 - mean_squared_error: 163.9041 - val_loss: 16.8206 - val_mean_squared_error: 16.8206\n",
            "Epoch 234/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 141.2967 - mean_squared_error: 141.2967 - val_loss: 15.9703 - val_mean_squared_error: 15.9703\n",
            "Epoch 235/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 147.1081 - mean_squared_error: 147.1081 - val_loss: 14.6960 - val_mean_squared_error: 14.6960\n",
            "Epoch 236/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 138.9491 - mean_squared_error: 138.9491 - val_loss: 16.9677 - val_mean_squared_error: 16.9677\n",
            "Epoch 237/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 143.7714 - mean_squared_error: 143.7714 - val_loss: 43.9348 - val_mean_squared_error: 43.9348\n",
            "Epoch 238/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 136.3492 - mean_squared_error: 136.3492 - val_loss: 16.8581 - val_mean_squared_error: 16.8581\n",
            "Epoch 239/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 132.8518 - mean_squared_error: 132.8518 - val_loss: 13.8453 - val_mean_squared_error: 13.8453\n",
            "Epoch 240/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 145.9012 - mean_squared_error: 145.9012 - val_loss: 14.3354 - val_mean_squared_error: 14.3354\n",
            "Epoch 241/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 134.2585 - mean_squared_error: 134.2585 - val_loss: 15.0677 - val_mean_squared_error: 15.0677\n",
            "Epoch 242/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 149.4158 - mean_squared_error: 149.4158 - val_loss: 14.9255 - val_mean_squared_error: 14.9255\n",
            "Epoch 243/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 151.1165 - mean_squared_error: 151.1165 - val_loss: 17.2617 - val_mean_squared_error: 17.2617\n",
            "Epoch 244/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 147.0179 - mean_squared_error: 147.0179 - val_loss: 13.8083 - val_mean_squared_error: 13.8083\n",
            "Epoch 245/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 136.0941 - mean_squared_error: 136.0941 - val_loss: 19.2781 - val_mean_squared_error: 19.2781\n",
            "Epoch 246/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 148.8703 - mean_squared_error: 148.8703 - val_loss: 18.7243 - val_mean_squared_error: 18.7243\n",
            "Epoch 247/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 132.2220 - mean_squared_error: 132.2220 - val_loss: 26.5218 - val_mean_squared_error: 26.5218\n",
            "Epoch 248/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 168.8884 - mean_squared_error: 168.8884 - val_loss: 37.1956 - val_mean_squared_error: 37.1956\n",
            "Epoch 249/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 141.2774 - mean_squared_error: 141.2774 - val_loss: 28.8580 - val_mean_squared_error: 28.8580\n",
            "Epoch 250/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 130.6665 - mean_squared_error: 130.6665 - val_loss: 15.0159 - val_mean_squared_error: 15.0159\n",
            "Epoch 251/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 139.9906 - mean_squared_error: 139.9906 - val_loss: 20.2169 - val_mean_squared_error: 20.2169\n",
            "Epoch 252/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 133.0873 - mean_squared_error: 133.0873 - val_loss: 18.6564 - val_mean_squared_error: 18.6564\n",
            "Epoch 253/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 138.2211 - mean_squared_error: 138.2211 - val_loss: 15.9691 - val_mean_squared_error: 15.9691\n",
            "Epoch 254/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 137.2214 - mean_squared_error: 137.2214 - val_loss: 20.5009 - val_mean_squared_error: 20.5009\n",
            "Epoch 255/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 135.8075 - mean_squared_error: 135.8075 - val_loss: 17.3266 - val_mean_squared_error: 17.3266\n",
            "Epoch 256/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 139.1283 - mean_squared_error: 139.1283 - val_loss: 14.5432 - val_mean_squared_error: 14.5432\n",
            "Epoch 257/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 140.4015 - mean_squared_error: 140.4015 - val_loss: 35.1523 - val_mean_squared_error: 35.1523\n",
            "Epoch 258/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 133.5324 - mean_squared_error: 133.5324 - val_loss: 18.8179 - val_mean_squared_error: 18.8179\n",
            "Epoch 259/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 124.5427 - mean_squared_error: 124.5427 - val_loss: 15.3303 - val_mean_squared_error: 15.3303\n",
            "Epoch 260/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 136.9671 - mean_squared_error: 136.9671 - val_loss: 12.2346 - val_mean_squared_error: 12.2346\n",
            "Epoch 261/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 123.0939 - mean_squared_error: 123.0939 - val_loss: 12.4721 - val_mean_squared_error: 12.4721\n",
            "Epoch 262/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 126.2250 - mean_squared_error: 126.2250 - val_loss: 17.9593 - val_mean_squared_error: 17.9593\n",
            "Epoch 263/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 135.8497 - mean_squared_error: 135.8497 - val_loss: 73.9217 - val_mean_squared_error: 73.9217\n",
            "Epoch 264/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 136.8912 - mean_squared_error: 136.8912 - val_loss: 12.9412 - val_mean_squared_error: 12.9412\n",
            "Epoch 265/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 122.9665 - mean_squared_error: 122.9665 - val_loss: 18.3958 - val_mean_squared_error: 18.3958\n",
            "Epoch 266/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 131.4543 - mean_squared_error: 131.4543 - val_loss: 9.2156 - val_mean_squared_error: 9.2156\n",
            "Epoch 267/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 122.0035 - mean_squared_error: 122.0035 - val_loss: 10.8235 - val_mean_squared_error: 10.8235\n",
            "Epoch 268/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 123.2502 - mean_squared_error: 123.2502 - val_loss: 11.5321 - val_mean_squared_error: 11.5321\n",
            "Epoch 269/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 137.0186 - mean_squared_error: 137.0186 - val_loss: 13.5902 - val_mean_squared_error: 13.5902\n",
            "Epoch 270/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 147.2327 - mean_squared_error: 147.2327 - val_loss: 35.7688 - val_mean_squared_error: 35.7688\n",
            "Epoch 271/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 124.3370 - mean_squared_error: 124.3370 - val_loss: 13.6755 - val_mean_squared_error: 13.6755\n",
            "Epoch 272/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 123.6582 - mean_squared_error: 123.6582 - val_loss: 11.9655 - val_mean_squared_error: 11.9655\n",
            "Epoch 273/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 129.0090 - mean_squared_error: 129.0090 - val_loss: 19.2721 - val_mean_squared_error: 19.2721\n",
            "Epoch 274/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 133.4219 - mean_squared_error: 133.4219 - val_loss: 12.9372 - val_mean_squared_error: 12.9372\n",
            "Epoch 275/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 118.8644 - mean_squared_error: 118.8644 - val_loss: 17.2935 - val_mean_squared_error: 17.2935\n",
            "Epoch 276/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 134.0531 - mean_squared_error: 134.0531 - val_loss: 19.0145 - val_mean_squared_error: 19.0145\n",
            "Epoch 277/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 138.3210 - mean_squared_error: 138.3210 - val_loss: 20.5464 - val_mean_squared_error: 20.5464\n",
            "Epoch 278/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 127.5638 - mean_squared_error: 127.5638 - val_loss: 12.0411 - val_mean_squared_error: 12.0411\n",
            "Epoch 279/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 131.4456 - mean_squared_error: 131.4456 - val_loss: 20.9044 - val_mean_squared_error: 20.9044\n",
            "Epoch 280/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 129.9851 - mean_squared_error: 129.9851 - val_loss: 24.4440 - val_mean_squared_error: 24.4440\n",
            "Epoch 281/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 119.8704 - mean_squared_error: 119.8704 - val_loss: 13.8460 - val_mean_squared_error: 13.8460\n",
            "Epoch 282/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 101.6037 - mean_squared_error: 101.6037 - val_loss: 13.5192 - val_mean_squared_error: 13.5192\n",
            "Epoch 283/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 131.0206 - mean_squared_error: 131.0206 - val_loss: 14.7250 - val_mean_squared_error: 14.7250\n",
            "Epoch 284/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 107.7068 - mean_squared_error: 107.7068 - val_loss: 10.9311 - val_mean_squared_error: 10.9311\n",
            "Epoch 285/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 132.9820 - mean_squared_error: 132.9820 - val_loss: 12.5576 - val_mean_squared_error: 12.5576\n",
            "Epoch 286/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 129.3685 - mean_squared_error: 129.3685 - val_loss: 16.3985 - val_mean_squared_error: 16.3985\n",
            "Epoch 287/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 110.3585 - mean_squared_error: 110.3585 - val_loss: 18.4892 - val_mean_squared_error: 18.4892\n",
            "Epoch 288/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 122.0663 - mean_squared_error: 122.0663 - val_loss: 13.1829 - val_mean_squared_error: 13.1829\n",
            "Epoch 289/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 113.3977 - mean_squared_error: 113.3977 - val_loss: 12.6296 - val_mean_squared_error: 12.6296\n",
            "Epoch 290/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 121.0611 - mean_squared_error: 121.0611 - val_loss: 15.7164 - val_mean_squared_error: 15.7164\n",
            "Epoch 291/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 110.5082 - mean_squared_error: 110.5082 - val_loss: 10.0557 - val_mean_squared_error: 10.0557\n",
            "Epoch 292/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 115.8969 - mean_squared_error: 115.8969 - val_loss: 22.0041 - val_mean_squared_error: 22.0041\n",
            "Epoch 293/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 108.3976 - mean_squared_error: 108.3976 - val_loss: 14.6872 - val_mean_squared_error: 14.6872\n",
            "Epoch 294/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 129.0992 - mean_squared_error: 129.0992 - val_loss: 17.9032 - val_mean_squared_error: 17.9032\n",
            "Epoch 295/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 115.6410 - mean_squared_error: 115.6410 - val_loss: 21.2033 - val_mean_squared_error: 21.2033\n",
            "Epoch 296/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 125.3376 - mean_squared_error: 125.3376 - val_loss: 14.3218 - val_mean_squared_error: 14.3218\n",
            "Epoch 297/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 121.9647 - mean_squared_error: 121.9647 - val_loss: 9.0727 - val_mean_squared_error: 9.0727\n",
            "Epoch 298/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 104.2409 - mean_squared_error: 104.2409 - val_loss: 9.4494 - val_mean_squared_error: 9.4494\n",
            "Epoch 299/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 135.1288 - mean_squared_error: 135.1288 - val_loss: 20.4939 - val_mean_squared_error: 20.4939\n",
            "Epoch 300/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 120.0858 - mean_squared_error: 120.0858 - val_loss: 10.8090 - val_mean_squared_error: 10.8090\n",
            "Epoch 301/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 131.5784 - mean_squared_error: 131.5784 - val_loss: 16.7771 - val_mean_squared_error: 16.7771\n",
            "Epoch 302/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 118.5484 - mean_squared_error: 118.5484 - val_loss: 15.0128 - val_mean_squared_error: 15.0128\n",
            "Epoch 303/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 123.4520 - mean_squared_error: 123.4520 - val_loss: 24.4047 - val_mean_squared_error: 24.4047\n",
            "Epoch 304/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 113.6617 - mean_squared_error: 113.6617 - val_loss: 21.0911 - val_mean_squared_error: 21.0911\n",
            "Epoch 305/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 145.2073 - mean_squared_error: 145.2073 - val_loss: 16.8040 - val_mean_squared_error: 16.8040\n",
            "Epoch 306/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 102.9459 - mean_squared_error: 102.9459 - val_loss: 15.0372 - val_mean_squared_error: 15.0372\n",
            "Epoch 307/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 113.5640 - mean_squared_error: 113.5640 - val_loss: 8.5794 - val_mean_squared_error: 8.5794\n",
            "Epoch 308/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 108.5852 - mean_squared_error: 108.5852 - val_loss: 10.9541 - val_mean_squared_error: 10.9541\n",
            "Epoch 309/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 121.1536 - mean_squared_error: 121.1536 - val_loss: 11.5928 - val_mean_squared_error: 11.5928\n",
            "Epoch 310/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 124.6377 - mean_squared_error: 124.6377 - val_loss: 23.4111 - val_mean_squared_error: 23.4111\n",
            "Epoch 311/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 120.1451 - mean_squared_error: 120.1451 - val_loss: 14.4134 - val_mean_squared_error: 14.4134\n",
            "Epoch 312/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 114.1281 - mean_squared_error: 114.1281 - val_loss: 18.9859 - val_mean_squared_error: 18.9859\n",
            "Epoch 313/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 134.0516 - mean_squared_error: 134.0516 - val_loss: 9.9403 - val_mean_squared_error: 9.9403\n",
            "Epoch 314/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 110.0915 - mean_squared_error: 110.0915 - val_loss: 9.0227 - val_mean_squared_error: 9.0227\n",
            "Epoch 315/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 109.4934 - mean_squared_error: 109.4934 - val_loss: 8.8111 - val_mean_squared_error: 8.8111\n",
            "Epoch 316/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 107.0943 - mean_squared_error: 107.0943 - val_loss: 12.9252 - val_mean_squared_error: 12.9252\n",
            "Epoch 317/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 132.2325 - mean_squared_error: 132.2325 - val_loss: 10.8980 - val_mean_squared_error: 10.8980\n",
            "Epoch 318/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 102.4276 - mean_squared_error: 102.4276 - val_loss: 10.8333 - val_mean_squared_error: 10.8333\n",
            "Epoch 319/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 110.4906 - mean_squared_error: 110.4906 - val_loss: 12.3685 - val_mean_squared_error: 12.3685\n",
            "Epoch 320/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 104.6539 - mean_squared_error: 104.6539 - val_loss: 8.7182 - val_mean_squared_error: 8.7182\n",
            "Epoch 321/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 109.1099 - mean_squared_error: 109.1099 - val_loss: 8.8199 - val_mean_squared_error: 8.8199\n",
            "Epoch 322/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 109.8456 - mean_squared_error: 109.8456 - val_loss: 7.2058 - val_mean_squared_error: 7.2058\n",
            "Epoch 323/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 139.2943 - mean_squared_error: 139.2943 - val_loss: 18.5623 - val_mean_squared_error: 18.5623\n",
            "Epoch 324/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 127.3167 - mean_squared_error: 127.3167 - val_loss: 7.4510 - val_mean_squared_error: 7.4510\n",
            "Epoch 325/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 119.6130 - mean_squared_error: 119.6130 - val_loss: 14.6400 - val_mean_squared_error: 14.6400\n",
            "Epoch 326/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 117.1632 - mean_squared_error: 117.1632 - val_loss: 12.3699 - val_mean_squared_error: 12.3699\n",
            "Epoch 327/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 109.4432 - mean_squared_error: 109.4432 - val_loss: 23.0814 - val_mean_squared_error: 23.0814\n",
            "Epoch 328/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 114.7117 - mean_squared_error: 114.7117 - val_loss: 24.2586 - val_mean_squared_error: 24.2586\n",
            "Epoch 329/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 129.1714 - mean_squared_error: 129.1714 - val_loss: 12.8476 - val_mean_squared_error: 12.8476\n",
            "Epoch 330/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 113.8463 - mean_squared_error: 113.8463 - val_loss: 6.7965 - val_mean_squared_error: 6.7965\n",
            "Epoch 331/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 118.5240 - mean_squared_error: 118.5240 - val_loss: 14.8933 - val_mean_squared_error: 14.8933\n",
            "Epoch 332/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 126.3366 - mean_squared_error: 126.3366 - val_loss: 15.1600 - val_mean_squared_error: 15.1600\n",
            "Epoch 333/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 109.2034 - mean_squared_error: 109.2034 - val_loss: 18.9446 - val_mean_squared_error: 18.9446\n",
            "Epoch 334/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 119.2142 - mean_squared_error: 119.2142 - val_loss: 7.5047 - val_mean_squared_error: 7.5047\n",
            "Epoch 335/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 107.1699 - mean_squared_error: 107.1699 - val_loss: 8.1727 - val_mean_squared_error: 8.1727\n",
            "Epoch 336/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 97.8358 - mean_squared_error: 97.8358 - val_loss: 6.8856 - val_mean_squared_error: 6.8856\n",
            "Epoch 337/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 127.5921 - mean_squared_error: 127.5921 - val_loss: 9.3367 - val_mean_squared_error: 9.3367\n",
            "Epoch 338/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 114.9469 - mean_squared_error: 114.9469 - val_loss: 7.6782 - val_mean_squared_error: 7.6782\n",
            "Epoch 339/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 94.7181 - mean_squared_error: 94.7181 - val_loss: 19.6193 - val_mean_squared_error: 19.6193\n",
            "Epoch 340/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 108.0490 - mean_squared_error: 108.0490 - val_loss: 15.0486 - val_mean_squared_error: 15.0486\n",
            "Epoch 341/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 112.6237 - mean_squared_error: 112.6237 - val_loss: 25.8016 - val_mean_squared_error: 25.8016\n",
            "Epoch 342/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 89.6185 - mean_squared_error: 89.6185 - val_loss: 8.4617 - val_mean_squared_error: 8.4617\n",
            "Epoch 343/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 104.6846 - mean_squared_error: 104.6846 - val_loss: 8.6687 - val_mean_squared_error: 8.6687\n",
            "Epoch 344/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 93.3568 - mean_squared_error: 93.3568 - val_loss: 18.8374 - val_mean_squared_error: 18.8374\n",
            "Epoch 345/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 107.4345 - mean_squared_error: 107.4345 - val_loss: 8.5736 - val_mean_squared_error: 8.5736\n",
            "Epoch 346/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 85.8662 - mean_squared_error: 85.8662 - val_loss: 8.4226 - val_mean_squared_error: 8.4226\n",
            "Epoch 347/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 99.9204 - mean_squared_error: 99.9204 - val_loss: 34.5177 - val_mean_squared_error: 34.5177\n",
            "Epoch 348/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 124.5624 - mean_squared_error: 124.5624 - val_loss: 6.9597 - val_mean_squared_error: 6.9597\n",
            "Epoch 349/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 104.7422 - mean_squared_error: 104.7422 - val_loss: 19.6688 - val_mean_squared_error: 19.6688\n",
            "Epoch 350/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 109.7514 - mean_squared_error: 109.7514 - val_loss: 27.0401 - val_mean_squared_error: 27.0401\n",
            "Epoch 351/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 115.2257 - mean_squared_error: 115.2257 - val_loss: 11.7060 - val_mean_squared_error: 11.7060\n",
            "Epoch 352/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 108.8831 - mean_squared_error: 108.8831 - val_loss: 6.7837 - val_mean_squared_error: 6.7837\n",
            "Epoch 353/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 98.5528 - mean_squared_error: 98.5528 - val_loss: 11.3572 - val_mean_squared_error: 11.3572\n",
            "Epoch 354/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 85.9783 - mean_squared_error: 85.9783 - val_loss: 7.7447 - val_mean_squared_error: 7.7447\n",
            "Epoch 355/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 117.2467 - mean_squared_error: 117.2467 - val_loss: 5.6767 - val_mean_squared_error: 5.6767\n",
            "Epoch 356/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 119.6052 - mean_squared_error: 119.6052 - val_loss: 12.8317 - val_mean_squared_error: 12.8317\n",
            "Epoch 357/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 108.0122 - mean_squared_error: 108.0122 - val_loss: 5.6324 - val_mean_squared_error: 5.6324\n",
            "Epoch 358/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 101.3150 - mean_squared_error: 101.3150 - val_loss: 7.1492 - val_mean_squared_error: 7.1492\n",
            "Epoch 359/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 90.8271 - mean_squared_error: 90.8271 - val_loss: 7.4977 - val_mean_squared_error: 7.4977\n",
            "Epoch 360/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 101.9768 - mean_squared_error: 101.9768 - val_loss: 11.0564 - val_mean_squared_error: 11.0564\n",
            "Epoch 361/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 118.6750 - mean_squared_error: 118.6750 - val_loss: 5.8069 - val_mean_squared_error: 5.8069\n",
            "Epoch 362/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 101.8524 - mean_squared_error: 101.8524 - val_loss: 8.2897 - val_mean_squared_error: 8.2897\n",
            "Epoch 363/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 99.6842 - mean_squared_error: 99.6842 - val_loss: 11.1094 - val_mean_squared_error: 11.1094\n",
            "Epoch 364/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 104.2827 - mean_squared_error: 104.2827 - val_loss: 14.5127 - val_mean_squared_error: 14.5127\n",
            "Epoch 365/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 110.6952 - mean_squared_error: 110.6952 - val_loss: 11.0215 - val_mean_squared_error: 11.0215\n",
            "Epoch 366/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 98.5320 - mean_squared_error: 98.5320 - val_loss: 18.4824 - val_mean_squared_error: 18.4824\n",
            "Epoch 367/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 108.0270 - mean_squared_error: 108.0270 - val_loss: 15.2140 - val_mean_squared_error: 15.2140\n",
            "Epoch 368/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 118.0742 - mean_squared_error: 118.0742 - val_loss: 7.9090 - val_mean_squared_error: 7.9090\n",
            "Epoch 369/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 121.6314 - mean_squared_error: 121.6314 - val_loss: 14.0962 - val_mean_squared_error: 14.0962\n",
            "Epoch 370/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 89.2815 - mean_squared_error: 89.2815 - val_loss: 5.8085 - val_mean_squared_error: 5.8085\n",
            "Epoch 371/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 127.3968 - mean_squared_error: 127.3968 - val_loss: 7.2890 - val_mean_squared_error: 7.2890\n",
            "Epoch 372/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 101.7449 - mean_squared_error: 101.7449 - val_loss: 10.0884 - val_mean_squared_error: 10.0884\n",
            "Epoch 373/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 106.3471 - mean_squared_error: 106.3471 - val_loss: 6.5418 - val_mean_squared_error: 6.5418\n",
            "Epoch 374/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 104.7715 - mean_squared_error: 104.7715 - val_loss: 19.1816 - val_mean_squared_error: 19.1816\n",
            "Epoch 375/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 108.0380 - mean_squared_error: 108.0380 - val_loss: 6.7680 - val_mean_squared_error: 6.7680\n",
            "Epoch 376/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 95.5554 - mean_squared_error: 95.5554 - val_loss: 7.7542 - val_mean_squared_error: 7.7542\n",
            "Epoch 377/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 98.3761 - mean_squared_error: 98.3761 - val_loss: 9.7177 - val_mean_squared_error: 9.7177\n",
            "Epoch 378/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 97.9537 - mean_squared_error: 97.9537 - val_loss: 46.8512 - val_mean_squared_error: 46.8512\n",
            "Epoch 379/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 90.0380 - mean_squared_error: 90.0380 - val_loss: 5.1330 - val_mean_squared_error: 5.1330\n",
            "Epoch 380/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 102.5149 - mean_squared_error: 102.5149 - val_loss: 8.7518 - val_mean_squared_error: 8.7518\n",
            "Epoch 381/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 99.7040 - mean_squared_error: 99.7040 - val_loss: 17.1412 - val_mean_squared_error: 17.1412\n",
            "Epoch 382/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 106.6405 - mean_squared_error: 106.6405 - val_loss: 6.6620 - val_mean_squared_error: 6.6620\n",
            "Epoch 383/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 85.8762 - mean_squared_error: 85.8762 - val_loss: 13.5522 - val_mean_squared_error: 13.5522\n",
            "Epoch 384/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 83.3217 - mean_squared_error: 83.3217 - val_loss: 8.9689 - val_mean_squared_error: 8.9689\n",
            "Epoch 385/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 97.5435 - mean_squared_error: 97.5435 - val_loss: 8.3558 - val_mean_squared_error: 8.3558\n",
            "Epoch 386/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 95.2517 - mean_squared_error: 95.2517 - val_loss: 12.4012 - val_mean_squared_error: 12.4012\n",
            "Epoch 387/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 93.0685 - mean_squared_error: 93.0685 - val_loss: 6.6569 - val_mean_squared_error: 6.6569\n",
            "Epoch 388/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 91.4183 - mean_squared_error: 91.4183 - val_loss: 12.0822 - val_mean_squared_error: 12.0822\n",
            "Epoch 389/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 91.5585 - mean_squared_error: 91.5585 - val_loss: 7.8045 - val_mean_squared_error: 7.8045\n",
            "Epoch 390/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 93.3905 - mean_squared_error: 93.3905 - val_loss: 10.0902 - val_mean_squared_error: 10.0902\n",
            "Epoch 391/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 89.5016 - mean_squared_error: 89.5016 - val_loss: 5.7002 - val_mean_squared_error: 5.7002\n",
            "Epoch 392/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 103.3541 - mean_squared_error: 103.3541 - val_loss: 7.6443 - val_mean_squared_error: 7.6443\n",
            "Epoch 393/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 89.2181 - mean_squared_error: 89.2181 - val_loss: 10.3928 - val_mean_squared_error: 10.3928\n",
            "Epoch 394/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 92.8126 - mean_squared_error: 92.8126 - val_loss: 7.6461 - val_mean_squared_error: 7.6461\n",
            "Epoch 395/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 105.9009 - mean_squared_error: 105.9009 - val_loss: 7.1680 - val_mean_squared_error: 7.1680\n",
            "Epoch 396/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 91.7032 - mean_squared_error: 91.7032 - val_loss: 8.1500 - val_mean_squared_error: 8.1500\n",
            "Epoch 397/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 77.1475 - mean_squared_error: 77.1475 - val_loss: 10.6469 - val_mean_squared_error: 10.6469\n",
            "Epoch 398/1000\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 104.1144 - mean_squared_error: 104.1144 - val_loss: 7.6267 - val_mean_squared_error: 7.6267\n",
            "Epoch 399/1000\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 102.4133 - mean_squared_error: 102.4133 - val_loss: 16.0084 - val_mean_squared_error: 16.0084\n",
            "Epoch 400/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 86.7359 - mean_squared_error: 86.7359 - val_loss: 4.6438 - val_mean_squared_error: 4.6438\n",
            "Epoch 401/1000\n",
            "72/72 [==============================] - 1s 12ms/step - loss: 107.5206 - mean_squared_error: 107.5206 - val_loss: 4.9877 - val_mean_squared_error: 4.9877\n",
            "Epoch 402/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 80.7519 - mean_squared_error: 80.7519 - val_loss: 12.3370 - val_mean_squared_error: 12.3370\n",
            "Epoch 403/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 85.0355 - mean_squared_error: 85.0355 - val_loss: 18.2224 - val_mean_squared_error: 18.2224\n",
            "Epoch 404/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 95.7400 - mean_squared_error: 95.7400 - val_loss: 13.8248 - val_mean_squared_error: 13.8248\n",
            "Epoch 405/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 93.0716 - mean_squared_error: 93.0716 - val_loss: 6.3476 - val_mean_squared_error: 6.3476\n",
            "Epoch 406/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 94.9165 - mean_squared_error: 94.9165 - val_loss: 4.1718 - val_mean_squared_error: 4.1718\n",
            "Epoch 407/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 103.5469 - mean_squared_error: 103.5469 - val_loss: 25.3669 - val_mean_squared_error: 25.3669\n",
            "Epoch 408/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 98.8932 - mean_squared_error: 98.8932 - val_loss: 13.4787 - val_mean_squared_error: 13.4787\n",
            "Epoch 409/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 94.0232 - mean_squared_error: 94.0232 - val_loss: 9.7212 - val_mean_squared_error: 9.7212\n",
            "Epoch 410/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 86.7624 - mean_squared_error: 86.7624 - val_loss: 11.3909 - val_mean_squared_error: 11.3909\n",
            "Epoch 411/1000\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 83.8634 - mean_squared_error: 83.8634 - val_loss: 6.4502 - val_mean_squared_error: 6.4502\n",
            "Epoch 412/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 92.3899 - mean_squared_error: 92.3899 - val_loss: 22.5528 - val_mean_squared_error: 22.5528\n",
            "Epoch 413/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 88.4939 - mean_squared_error: 88.4939 - val_loss: 6.4867 - val_mean_squared_error: 6.4867\n",
            "Epoch 414/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 84.2785 - mean_squared_error: 84.2785 - val_loss: 6.5719 - val_mean_squared_error: 6.5719\n",
            "Epoch 415/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 91.2133 - mean_squared_error: 91.2133 - val_loss: 5.4581 - val_mean_squared_error: 5.4581\n",
            "Epoch 416/1000\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 109.6163 - mean_squared_error: 109.6163 - val_loss: 4.6903 - val_mean_squared_error: 4.6903\n",
            "Epoch 417/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 79.8660 - mean_squared_error: 79.8660 - val_loss: 3.0005 - val_mean_squared_error: 3.0005\n",
            "Epoch 418/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 103.5793 - mean_squared_error: 103.5793 - val_loss: 7.0937 - val_mean_squared_error: 7.0937\n",
            "Epoch 419/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 97.6546 - mean_squared_error: 97.6546 - val_loss: 10.5528 - val_mean_squared_error: 10.5528\n",
            "Epoch 420/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 89.4388 - mean_squared_error: 89.4388 - val_loss: 9.5787 - val_mean_squared_error: 9.5787\n",
            "Epoch 421/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 87.5494 - mean_squared_error: 87.5494 - val_loss: 8.5459 - val_mean_squared_error: 8.5459\n",
            "Epoch 422/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 94.9024 - mean_squared_error: 94.9024 - val_loss: 6.2400 - val_mean_squared_error: 6.2400\n",
            "Epoch 423/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 79.6792 - mean_squared_error: 79.6792 - val_loss: 6.7730 - val_mean_squared_error: 6.7730\n",
            "Epoch 424/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 83.5340 - mean_squared_error: 83.5340 - val_loss: 9.1233 - val_mean_squared_error: 9.1233\n",
            "Epoch 425/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 81.1552 - mean_squared_error: 81.1552 - val_loss: 4.7363 - val_mean_squared_error: 4.7363\n",
            "Epoch 426/1000\n",
            "17/72 [======>.......................] - ETA: 0s - loss: 119.2070 - mean_squared_error: 119.2070"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPduEgiqcyT3subzhas5llu"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}